{
  "last_node_id": 29,
  "last_link_id": 35,
  "nodes": [
    {
      "id": 17,
      "type": "PreviewImage",
      "pos": [
        3720,
        639
      ],
      "size": {
        "0": 692.623046875,
        "1": 616.8628540039062
      },
      "flags": {
        "collapsed": false
      },
      "order": 22,
      "mode": 0,
      "inputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "link": 32
        }
      ],
      "properties": {
        "Node name for S&R": "PreviewImage"
      }
    },
    {
      "id": 13,
      "type": "VAEDecode",
      "pos": [
        2352.73291015625,
        253.00000000000003
      ],
      "size": {
        "0": 140,
        "1": 46
      },
      "flags": {},
      "order": 19,
      "mode": 0,
      "inputs": [
        {
          "name": "samples",
          "type": "LATENT",
          "link": 26
        },
        {
          "name": "vae",
          "type": "VAE",
          "link": 11
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [
            15
          ],
          "shape": 3,
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "VAEDecode"
      },
      "color": "#223",
      "bgcolor": "#335"
    },
    {
      "id": 18,
      "type": "InsightFaceLoader",
      "pos": [
        2564,
        -298
      ],
      "size": {
        "0": 315,
        "1": 58
      },
      "flags": {},
      "order": 0,
      "mode": 0,
      "outputs": [
        {
          "name": "INSIGHTFACE",
          "type": "INSIGHTFACE",
          "links": [
            5,
            20
          ],
          "shape": 3,
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "InsightFaceLoader"
      },
      "widgets_values": [
        "CPU"
      ]
    },
    {
      "id": 5,
      "type": "EmptyLatentImage",
      "pos": [
        1502,
        1117
      ],
      "size": [
        210,
        106
      ],
      "flags": {
        "collapsed": false
      },
      "order": 1,
      "mode": 0,
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": [
            25,
            27
          ],
          "shape": 3,
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "EmptyLatentImage"
      },
      "widgets_values": [
        512,
        512,
        1
      ],
      "shape": 2
    },
    {
      "id": 27,
      "type": "VAEDecode",
      "pos": [
        3910,
        390
      ],
      "size": {
        "0": 140,
        "1": 46
      },
      "flags": {},
      "order": 20,
      "mode": 0,
      "inputs": [
        {
          "name": "samples",
          "type": "LATENT",
          "link": 33,
          "slot_index": 0
        },
        {
          "name": "vae",
          "type": "VAE",
          "link": 12
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [
            32
          ],
          "shape": 3,
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "VAEDecode"
      },
      "color": "#223",
      "bgcolor": "#335"
    },
    {
      "id": 6,
      "type": "CLIPVisionLoader",
      "pos": [
        1392.73291015625,
        113
      ],
      "size": {
        "0": 315,
        "1": 58
      },
      "flags": {},
      "order": 2,
      "mode": 0,
      "outputs": [
        {
          "name": "CLIP_VISION",
          "type": "CLIP_VISION",
          "links": [
            2
          ],
          "shape": 3
        }
      ],
      "properties": {
        "Node name for S&R": "CLIPVisionLoader"
      },
      "widgets_values": [
        "SD1.5\\pytorch_model.bin"
      ],
      "color": "#223",
      "bgcolor": "#335"
    },
    {
      "id": 10,
      "type": "IPAdapterModelLoader",
      "pos": [
        1852.7329101562498,
        -100
      ],
      "size": {
        "0": 315,
        "1": 58
      },
      "flags": {},
      "order": 3,
      "mode": 0,
      "outputs": [
        {
          "name": "IPADAPTER",
          "type": "IPADAPTER",
          "links": [
            1
          ],
          "shape": 3,
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "IPAdapterModelLoader"
      },
      "widgets_values": [
        "ip-adapter-faceid_sd15.bin"
      ],
      "color": "#223",
      "bgcolor": "#335"
    },
    {
      "id": 9,
      "type": "IPAdapterApplyFaceID",
      "pos": [
        1844.7329101562498,
        73
      ],
      "size": {
        "0": 315,
        "1": 326
      },
      "flags": {},
      "order": 15,
      "mode": 0,
      "inputs": [
        {
          "name": "ipadapter",
          "type": "IPADAPTER",
          "link": 1
        },
        {
          "name": "clip_vision",
          "type": "CLIP_VISION",
          "link": 2,
          "slot_index": 1
        },
        {
          "name": "insightface",
          "type": "INSIGHTFACE",
          "link": 5
        },
        {
          "name": "image",
          "type": "IMAGE",
          "link": 4
        },
        {
          "name": "model",
          "type": "MODEL",
          "link": 6,
          "slot_index": 4
        },
        {
          "name": "attn_mask",
          "type": "MASK",
          "link": null
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            3
          ],
          "shape": 3
        }
      ],
      "properties": {
        "Node name for S&R": "IPAdapterApplyFaceID"
      },
      "widgets_values": [
        0.8,
        0.01,
        "original",
        0,
        1,
        false,
        1,
        false
      ],
      "color": "#223",
      "bgcolor": "#335"
    },
    {
      "id": 8,
      "type": "LoraLoaderModelOnly",
      "pos": [
        1381.73291015625,
        398
      ],
      "size": {
        "0": 315,
        "1": 82
      },
      "flags": {},
      "order": 11,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 8,
          "slot_index": 0
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            6
          ],
          "shape": 3
        }
      ],
      "properties": {
        "Node name for S&R": "LoraLoaderModelOnly"
      },
      "widgets_values": [
        "ip-adapter-faceid_sd15_lora.safetensors",
        0.5
      ],
      "color": "#223",
      "bgcolor": "#335"
    },
    {
      "id": 7,
      "type": "PrepImageForClipVision",
      "pos": [
        1387.73291015625,
        234.00000000000003
      ],
      "size": {
        "0": 315,
        "1": 106
      },
      "flags": {},
      "order": 9,
      "mode": 0,
      "inputs": [
        {
          "name": "image",
          "type": "IMAGE",
          "link": 7,
          "slot_index": 0
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [
            4
          ],
          "shape": 3,
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "PrepImageForClipVision"
      },
      "widgets_values": [
        "LANCZOS",
        "pad",
        0
      ],
      "color": "#223",
      "bgcolor": "#335"
    },
    {
      "id": 11,
      "type": "KSampler",
      "pos": [
        2273.73291015625,
        -77
      ],
      "size": {
        "0": 315,
        "1": 262
      },
      "flags": {},
      "order": 17,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 3,
          "slot_index": 0
        },
        {
          "name": "positive",
          "type": "CONDITIONING",
          "link": 23
        },
        {
          "name": "negative",
          "type": "CONDITIONING",
          "link": 24
        },
        {
          "name": "latent_image",
          "type": "LATENT",
          "link": 25
        }
      ],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": [
            26
          ],
          "shape": 3,
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "KSampler"
      },
      "widgets_values": [
        502031461323733,
        "randomize",
        25,
        6,
        "dpmpp_2m",
        "karras",
        1
      ],
      "color": "#223",
      "bgcolor": "#335"
    },
    {
      "id": 16,
      "type": "PreviewImage",
      "pos": [
        2736,
        654
      ],
      "size": [
        692.6230710156246,
        616.862875478515
      ],
      "flags": {
        "collapsed": false
      },
      "order": 21,
      "mode": 0,
      "inputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "link": 15,
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "PreviewImage"
      },
      "color": "#223",
      "bgcolor": "#335"
    },
    {
      "id": 29,
      "type": "PrepImageForInsightFace",
      "pos": [
        3037,
        206
      ],
      "size": {
        "0": 315,
        "1": 106
      },
      "flags": {},
      "order": 10,
      "mode": 0,
      "inputs": [
        {
          "name": "image",
          "type": "IMAGE",
          "link": 35
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [
            34
          ],
          "shape": 3,
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "PrepImageForInsightFace"
      },
      "widgets_values": [
        "center",
        0,
        true
      ],
      "color": "#223",
      "bgcolor": "#335"
    },
    {
      "id": 21,
      "type": "CLIPVisionLoader",
      "pos": [
        3022,
        95
      ],
      "size": {
        "0": 315,
        "1": 58
      },
      "flags": {},
      "order": 4,
      "mode": 0,
      "outputs": [
        {
          "name": "CLIP_VISION",
          "type": "CLIP_VISION",
          "links": [
            19
          ],
          "shape": 3,
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "CLIPVisionLoader"
      },
      "widgets_values": [
        "CLIP-ViT-H-14-laion2B-s32B-b79K.safetensors"
      ],
      "color": "#223",
      "bgcolor": "#335"
    },
    {
      "id": 23,
      "type": "LoraLoaderModelOnly",
      "pos": [
        3026,
        387
      ],
      "size": {
        "0": 315,
        "1": 82
      },
      "flags": {},
      "order": 12,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 13
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            17
          ],
          "shape": 3,
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "LoraLoaderModelOnly"
      },
      "widgets_values": [
        "ip-adapter-faceid-plusv2_sd15_lora.safetensors",
        0.5
      ],
      "color": "#223",
      "bgcolor": "#335"
    },
    {
      "id": 25,
      "type": "IPAdapterModelLoader",
      "pos": [
        3419,
        -134
      ],
      "size": {
        "0": 315,
        "1": 58
      },
      "flags": {},
      "order": 5,
      "mode": 0,
      "outputs": [
        {
          "name": "IPADAPTER",
          "type": "IPADAPTER",
          "links": [
            21
          ],
          "shape": 3
        }
      ],
      "properties": {
        "Node name for S&R": "IPAdapterModelLoader"
      },
      "widgets_values": [
        "ip-adapter-faceid-plusv2_sd15.bin"
      ],
      "color": "#223",
      "bgcolor": "#335"
    },
    {
      "id": 26,
      "type": "KSampler",
      "pos": [
        3851,
        43
      ],
      "size": {
        "0": 315,
        "1": 262
      },
      "flags": {},
      "order": 18,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 22
        },
        {
          "name": "positive",
          "type": "CONDITIONING",
          "link": 30
        },
        {
          "name": "negative",
          "type": "CONDITIONING",
          "link": 31
        },
        {
          "name": "latent_image",
          "type": "LATENT",
          "link": 27
        }
      ],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": [
            33
          ],
          "shape": 3
        }
      ],
      "properties": {
        "Node name for S&R": "KSampler"
      },
      "widgets_values": [
        665823746010696,
        "randomize",
        25,
        6,
        "dpmpp_2m",
        "karras",
        1
      ],
      "color": "#223",
      "bgcolor": "#335"
    },
    {
      "id": 24,
      "type": "IPAdapterApplyFaceID",
      "pos": [
        3420,
        9
      ],
      "size": {
        "0": 315,
        "1": 326
      },
      "flags": {},
      "order": 16,
      "mode": 0,
      "inputs": [
        {
          "name": "ipadapter",
          "type": "IPADAPTER",
          "link": 21,
          "slot_index": 0
        },
        {
          "name": "clip_vision",
          "type": "CLIP_VISION",
          "link": 19
        },
        {
          "name": "insightface",
          "type": "INSIGHTFACE",
          "link": 20
        },
        {
          "name": "image",
          "type": "IMAGE",
          "link": 34
        },
        {
          "name": "model",
          "type": "MODEL",
          "link": 17
        },
        {
          "name": "attn_mask",
          "type": "MASK",
          "link": null
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            22
          ],
          "shape": 3,
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "IPAdapterApplyFaceID"
      },
      "widgets_values": [
        0.8,
        0.01,
        "original",
        0,
        1,
        true,
        1,
        false
      ],
      "color": "#223",
      "bgcolor": "#335"
    },
    {
      "id": 4,
      "type": "CLIPTextEncode",
      "pos": [
        1417,
        854
      ],
      "size": {
        "0": 400,
        "1": 200
      },
      "flags": {},
      "order": 14,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 10
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "links": [
            24,
            31
          ],
          "shape": 3,
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "CLIPTextEncode"
      },
      "widgets_values": [
        "Adults, cities, electronics, other children, animals, signage, vehicles, water bodies, picnic gear, toys, bad weather, groups"
      ],
      "color": "#322",
      "bgcolor": "#533"
    },
    {
      "id": 15,
      "type": "LoadImage",
      "pos": [
        1941,
        645
      ],
      "size": [
        715.1599928515616,
        628.0730762499993
      ],
      "flags": {},
      "order": 6,
      "mode": 0,
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [
            7,
            35
          ],
          "shape": 3,
          "slot_index": 0
        },
        {
          "name": "MASK",
          "type": "MASK",
          "links": null,
          "shape": 3
        }
      ],
      "properties": {
        "Node name for S&R": "LoadImage"
      },
      "widgets_values": [
        "ComfyUI_00002_ (6).png",
        "image"
      ],
      "color": "#323",
      "bgcolor": "#535"
    },
    {
      "id": 2,
      "type": "CheckpointLoaderSimple",
      "pos": [
        901,
        577
      ],
      "size": {
        "0": 315,
        "1": 98
      },
      "flags": {},
      "order": 7,
      "mode": 0,
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            8,
            13
          ],
          "shape": 3,
          "slot_index": 0
        },
        {
          "name": "CLIP",
          "type": "CLIP",
          "links": [
            9,
            10
          ],
          "shape": 3,
          "slot_index": 1
        },
        {
          "name": "VAE",
          "type": "VAE",
          "links": [
            11,
            12
          ],
          "shape": 3,
          "slot_index": 2
        }
      ],
      "properties": {
        "Node name for S&R": "CheckpointLoaderSimple"
      },
      "widgets_values": [
        "Realistic_Vision_V6.0_NV_B1_fp16.safetensors"
      ]
    },
    {
      "id": 14,
      "type": "VAELoader",
      "pos": [
        915,
        743
      ],
      "size": {
        "0": 315,
        "1": 58
      },
      "flags": {},
      "order": 8,
      "mode": 0,
      "outputs": [
        {
          "name": "VAE",
          "type": "VAE",
          "links": null,
          "shape": 3
        }
      ],
      "properties": {
        "Node name for S&R": "VAELoader"
      },
      "widgets_values": [
        "orangemix.vae.pt"
      ]
    },
    {
      "id": 3,
      "type": "CLIPTextEncode",
      "pos": [
        1423,
        603
      ],
      "size": {
        "0": 400,
        "1": 200
      },
      "flags": {},
      "order": 13,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 9
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "links": [
            23,
            30
          ],
          "shape": 3,
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "CLIPTextEncode"
      },
      "widgets_values": [
        "\nChild, young smiling child with a playful expression,\nExplorer, dressed for an adventure with a backpack,\nForest, surrounded by dense green foliage and trees,\nSmiling, a bright and cheerful smile looking over the shoulder,\nAdventure, ready for exploration or a hike,\nDaylight, natural daylight filtering through the trees,\nBackpack, red with golden zippers, suggesting preparedness,\nHat, blue and round-brimmed, outdoor apparel,\nNature, immersed in a natural, verdant environment,\nJoyful, exhibiting a sense of happiness and enjoyment in nature.\n\n\n\n"
      ],
      "color": "#232",
      "bgcolor": "#353"
    }
  ],
  "links": [
    [
      1,
      10,
      0,
      9,
      0,
      "IPADAPTER"
    ],
    [
      2,
      6,
      0,
      9,
      1,
      "CLIP_VISION"
    ],
    [
      3,
      9,
      0,
      11,
      0,
      "MODEL"
    ],
    [
      4,
      7,
      0,
      9,
      3,
      "IMAGE"
    ],
    [
      5,
      18,
      0,
      9,
      2,
      "INSIGHTFACE"
    ],
    [
      6,
      8,
      0,
      9,
      4,
      "MODEL"
    ],
    [
      7,
      15,
      0,
      7,
      0,
      "IMAGE"
    ],
    [
      8,
      2,
      0,
      8,
      0,
      "MODEL"
    ],
    [
      9,
      2,
      1,
      3,
      0,
      "CLIP"
    ],
    [
      10,
      2,
      1,
      4,
      0,
      "CLIP"
    ],
    [
      11,
      2,
      2,
      13,
      1,
      "VAE"
    ],
    [
      12,
      2,
      2,
      27,
      1,
      "VAE"
    ],
    [
      13,
      2,
      0,
      23,
      0,
      "MODEL"
    ],
    [
      15,
      13,
      0,
      16,
      0,
      "IMAGE"
    ],
    [
      17,
      23,
      0,
      24,
      4,
      "MODEL"
    ],
    [
      19,
      21,
      0,
      24,
      1,
      "CLIP_VISION"
    ],
    [
      20,
      18,
      0,
      24,
      2,
      "INSIGHTFACE"
    ],
    [
      21,
      25,
      0,
      24,
      0,
      "IPADAPTER"
    ],
    [
      22,
      24,
      0,
      26,
      0,
      "MODEL"
    ],
    [
      23,
      3,
      0,
      11,
      1,
      "CONDITIONING"
    ],
    [
      24,
      4,
      0,
      11,
      2,
      "CONDITIONING"
    ],
    [
      25,
      5,
      0,
      11,
      3,
      "LATENT"
    ],
    [
      26,
      11,
      0,
      13,
      0,
      "LATENT"
    ],
    [
      27,
      5,
      0,
      26,
      3,
      "LATENT"
    ],
    [
      30,
      3,
      0,
      26,
      1,
      "CONDITIONING"
    ],
    [
      31,
      4,
      0,
      26,
      2,
      "CONDITIONING"
    ],
    [
      32,
      27,
      0,
      17,
      0,
      "IMAGE"
    ],
    [
      33,
      26,
      0,
      27,
      0,
      "LATENT"
    ],
    [
      34,
      29,
      0,
      24,
      3,
      "IMAGE"
    ],
    [
      35,
      15,
      0,
      29,
      0,
      "IMAGE"
    ]
  ],
  "groups": [
    {
      "title": "FaceID - IPAdapter",
      "bounding": [
        1372,
        -174,
        1227,
        664
      ],
      "color": "#b06634",
      "font_size": 24
    },
    {
      "title": "FaceID Plus V2-IPAdapter",
      "bounding": [
        3012,
        -208,
        1217,
        724
      ],
      "color": "#b58b2a",
      "font_size": 24
    }
  ],
  "config": {},
  "extra": {
    "groupNodes": {
      "FaceID-IPAdapter": {
        "nodes": [
          {
            "type": "LoraLoaderModelOnly",
            "pos": [
              1381,
              398
            ],
            "size": {
              "0": 315,
              "1": 82
            },
            "flags": {},
            "order": 10,
            "mode": 0,
            "inputs": [
              {
                "name": "model",
                "type": "MODEL",
                "link": null
              }
            ],
            "outputs": [
              {
                "name": "MODEL",
                "type": "MODEL",
                "links": null,
                "shape": 3
              }
            ],
            "properties": {
              "Node name for S&R": "LoraLoaderModelOnly"
            },
            "widgets_values": [
              "Harrlogos_v2.0.safetensors",
              1
            ],
            "color": "#223",
            "bgcolor": "#335",
            "index": 0
          },
          {
            "type": "PrepImageForClipVision",
            "pos": [
              1387,
              234
            ],
            "size": {
              "0": 315,
              "1": 106
            },
            "flags": {},
            "order": 11,
            "mode": 0,
            "inputs": [
              {
                "name": "image",
                "type": "IMAGE",
                "link": null
              }
            ],
            "outputs": [
              {
                "name": "IMAGE",
                "type": "IMAGE",
                "links": null,
                "shape": 3
              }
            ],
            "properties": {
              "Node name for S&R": "PrepImageForClipVision"
            },
            "widgets_values": [
              "LANCZOS",
              "top",
              0
            ],
            "color": "#223",
            "bgcolor": "#335",
            "index": 1
          },
          {
            "type": "IPAdapterApplyFaceID",
            "pos": [
              1844,
              73
            ],
            "size": {
              "0": 315,
              "1": 326
            },
            "flags": {},
            "order": 20,
            "mode": 0,
            "inputs": [
              {
                "name": "ipadapter",
                "type": "IPADAPTER",
                "link": null
              },
              {
                "name": "clip_vision",
                "type": "CLIP_VISION",
                "link": null
              },
              {
                "name": "insightface",
                "type": "INSIGHTFACE",
                "link": null
              },
              {
                "name": "image",
                "type": "IMAGE",
                "link": null
              },
              {
                "name": "model",
                "type": "MODEL",
                "link": null
              },
              {
                "name": "attn_mask",
                "type": "MASK",
                "link": null
              }
            ],
            "outputs": [
              {
                "name": "MODEL",
                "type": "MODEL",
                "links": null,
                "shape": 3
              }
            ],
            "properties": {
              "Node name for S&R": "IPAdapterApplyFaceID"
            },
            "widgets_values": [
              1,
              0,
              "original",
              0,
              1,
              false,
              1,
              false
            ],
            "color": "#223",
            "bgcolor": "#335",
            "index": 2
          },
          {
            "type": "IPAdapterModelLoader",
            "pos": [
              1852,
              -100
            ],
            "size": {
              "0": 315,
              "1": 58
            },
            "flags": {},
            "order": 21,
            "mode": 0,
            "outputs": [
              {
                "name": "IPADAPTER",
                "type": "IPADAPTER",
                "links": null,
                "shape": 3
              }
            ],
            "properties": {
              "Node name for S&R": "IPAdapterModelLoader"
            },
            "widgets_values": [
              "ip-adapter-faceid-plusv2_sd15 (1).bin"
            ],
            "color": "#223",
            "bgcolor": "#335",
            "index": 3
          },
          {
            "type": "KSampler",
            "pos": [
              2273,
              -77
            ],
            "size": {
              "0": 315,
              "1": 262
            },
            "flags": {},
            "order": 22,
            "mode": 0,
            "inputs": [
              {
                "name": "model",
                "type": "MODEL",
                "link": null
              },
              {
                "name": "positive",
                "type": "CONDITIONING",
                "link": null
              },
              {
                "name": "negative",
                "type": "CONDITIONING",
                "link": null
              },
              {
                "name": "latent_image",
                "type": "LATENT",
                "link": null
              }
            ],
            "outputs": [
              {
                "name": "LATENT",
                "type": "LATENT",
                "links": null,
                "shape": 3
              }
            ],
            "properties": {
              "Node name for S&R": "KSampler"
            },
            "widgets_values": [
              0,
              "randomize",
              20,
              8,
              "euler",
              "normal",
              1
            ],
            "color": "#223",
            "bgcolor": "#335",
            "index": 4
          },
          {
            "type": "VAEDecode",
            "pos": [
              2352,
              253
            ],
            "size": {
              "0": 140,
              "1": 46
            },
            "flags": {},
            "order": 23,
            "mode": 0,
            "inputs": [
              {
                "name": "samples",
                "type": "LATENT",
                "link": null
              },
              {
                "name": "vae",
                "type": "VAE",
                "link": null
              }
            ],
            "outputs": [
              {
                "name": "IMAGE",
                "type": "IMAGE",
                "links": null,
                "shape": 3
              }
            ],
            "properties": {
              "Node name for S&R": "VAEDecode"
            },
            "color": "#223",
            "bgcolor": "#335",
            "index": 5
          },
          {
            "type": "CLIPVisionLoader",
            "pos": [
              1392,
              113
            ],
            "size": {
              "0": 315,
              "1": 58
            },
            "flags": {},
            "order": 24,
            "mode": 0,
            "outputs": [
              {
                "name": "CLIP_VISION",
                "type": "CLIP_VISION",
                "links": null,
                "shape": 3
              }
            ],
            "properties": {
              "Node name for S&R": "CLIPVisionLoader"
            },
            "widgets_values": [
              "CLIP-ViT-H-14-laion2B-s32B-b79K.safetensors"
            ],
            "color": "#223",
            "bgcolor": "#335",
            "index": 6
          }
        ],
        "links": [],
        "external": []
      }
    }
  },
  "version": 0.4
}